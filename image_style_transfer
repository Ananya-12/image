import numpy as np
import cv2
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input, decode_predictions
from keras import backend
from keras.models import Model
from scipy.optimize import fmin_l_bfgs_b
 
content_image='/home/ananya/Documents/ananya/vision/content_image.jpeg'
style_image='/home/ananya/Documents/ananya/vision/style_image.jpg'
content_image=cv2.imread(content_image)
content_image=cv2.cvtColor(content_image,cv2.COLOR_BGR2RGB)
style_image=cv2.imread(style_image)
style_image=cv2.cvtColor(style_image,cv2.COLOR_BGR2RGB)
content_image = cv2.resize(content_image, (512, 512))
style_image = cv2.resize(style_image, (512, 512))
content_array=np.asarray(content_image,dtype='float32')
content_array=np.expand_dims(content_array,axis=0)
style_array=np.asarray(style_image,dtype='float32')
style_array=np.expand_dims(style_array,axis=0)



content_image=backend.variable(content_array)
style_image=backend.variable(style_array)
output_image=backend.placeholder((1,512,512,3))

input_tensor=backend.concatenate([content_image,style_image,output_image],axis=0)

model=VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)

content_weight=0.05
style_weight=5.0
total_variation_weight=1.0

layers=dict([layer.name,layer.output] for layer in model.layers)

loss=backend.variable(0.)

def content_loss(content,combination):
    return backend.sum(backend.square(content-combination))
layer_features=layers['block2_conv2']
content_image_features=layer_features[0,:,:,:]
output_image_features=layer_features[2,:,:,:]

loss+=content_weight*content_loss(content_image_features,output_image_features)

def gram_matrix(x):
    features=backend.batch_flatten(backend.permute_dimensions(x,(2,0,1)))
    gram=backend.dot(features, backend.transpose(features))
    return gram

def style_loss(style, combinations):
    s=gram_matrix(style)
    c=gram_matrix(combinations)
    channel=3
    size= 512*512
    st= backend.sum(backend.square(s-c)/4*(channel**2)*(size**2))
    return st




feature_layers= ['block1_conv2' , 'block2_conv2' , 'block3_conv3' , 'block4_conv3' , 'block5_conv3']


for l_n in feature_layers:
    layer_fatures= layers[l_n]
    style_feature=layer_features[1,:,:,:]
    output_feature=layer_features[2,:,:,:]
    sl=style_loss(style_feature,output_feature)
    loss+=(style_weight/len(feature_layers))*sl


def total_variation_loss(x):
    a=backend.square(x[:,:(512-1),:(512-1),:]-x[:,1:,:(512-1),:])
    b=backend.square(x[:,:(512-1),:(512-1),:]-x[:,:(512-1),1:,:])
    return backend.sum(backend.pow(a+b,1.25))


loss+=total_variation_weight*total_variation_loss(output_image)

gradient=backend.gradients(loss, output_image)
outputs=[loss] 
if isinstance( gradient, (list, tuple)):
   outputs+= gradient
else: 
   output.append(gradient)
f_output=backend.function([output_image],outputs)


def eval_loss_and_grads(x):
    x=x.reshape((1,512,512,3))
    o=f_output([x])
    loss_value=o[0]
    grad_value=o[1].flatten().astype('float64')
    return loss_value, grad_value


class Evaluator(object):
      def __init__(self):
          self.loss_value=None
          self.grads_value=None
      def loss(self, x):
          assert self.loss_value is None
          loss_value, grad_value = eval_loss_and_grads(x)
          self.loss_value=loss_value
          self.grad_value=grad_value
      def grads(self, x):
          assert self.loss_value is not None
          grad_value=np.copy(self.grad_value)
          self.loss_value=None
          self.grads_value=None
          return grad_value


evaluator=Evaluator()


x=np.random.uniform(0,255,(1,512,512,3))-128.0




for i in range(10):
    print('start of iteration', i  )
   
    x, min_val ,info=fmin_l_bfgs_b(evaluator.loss, x.flatten(),fprime=evaluator.grads, maxfun=20)
    print(min_val)
    


plt.imshow(output_image)
plt.show()
